{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c34afe-2b99-4de0-a5db-3a67bde048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pylab as plt\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import vit_pytorch\n",
    "import einops\n",
    "import copy\n",
    "from munch import Munch\n",
    "import h5py\n",
    "import re\n",
    "from functools import reduce\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5694a28-b1f0-4a7d-ae9c-5daf4b65f6a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37fc949-00e1-4128-8727-e8c470e18e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/autodl-tmp/samples/tt0120903_1134.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_1196.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_1274.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_1349.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_146.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_161.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_173.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_299.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_352.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_353.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_369.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_543.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_557.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_582.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_587.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_736.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_938.png',\n",
       " '/root/autodl-tmp/samples/tt0120903_982.png']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_root = '/root/autodl-tmp/samples'\n",
    "img_paths = [os.path.join(img_root, name) for name in os.listdir(img_root)]\n",
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a844e4e2-466f-4ae1-a35d-cb4d4bdb7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae174259-2441-413c-a041-20b72facf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [Image.open(path) for path in img_paths]\n",
    "tensors = torch.stack([trans(img) for img in imgs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727ad6f-7e38-424b-bb06-b0ced18b430c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# bassl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7931fa36-3901-4191-921b-f254ae46789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bassl_params = torch.load('/root/autodl-tmp/bassl40epoch/model-v1-1.ckpt', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdf85ab-3efb-42c1-9cd3-e358ee93bc57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for k,v in bassl_params['state_dict'].items():\n",
    "    if k.startswith('shot_encoder.'):\n",
    "        params[k[13:]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb995ea-80ec-41c5-84c6-77f956ff4e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resnet.resnet import resnet50\n",
    "bassl = resnet50()\n",
    "bassl.eval()\n",
    "bassl.requires_grad_(False)\n",
    "bassl.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a80f635-cd74-44f0-a305-ba37996023af",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = bassl(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546efc83-3a80-4676-af30-21fe0aa5d07e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# shotcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd55b619-7f80-49dd-82fe-7b27a6c488be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shotcol_params = torch.load('/root/autodl-tmp/simclr_nn/model-v1-1.ckpt', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e3c0d3-8726-473b-857b-5d25df70cff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for k,v in shotcol_params['state_dict'].items():\n",
    "    if k.startswith('shot_encoder.'):\n",
    "        params[k[13:]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678ddeba-04f7-47d3-9fe9-1a87d2215da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from resnet.resnet import resnet50\n",
    "shotcol = resnet50()\n",
    "shotcol.eval()\n",
    "shotcol.requires_grad_(False)\n",
    "shotcol.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c94c9971-df7c-4581-a4d2-becc4323b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = shotcol(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e40c9-07e0-4007-bd2f-7e0614fb2a54",
   "metadata": {},
   "source": [
    "# imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bf5571-0ffc-4038-a425-4435b59fd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = nn.Sequential(*list(models.resnet50(True).children())[:-2])\n",
    "imagenet.eval()\n",
    "imagenet.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97c3a8a-a733-45a1-856a-ce6e28fcc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imagenet(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e83844-4cdc-401f-9569-ba59bcbb4407",
   "metadata": {},
   "source": [
    "# places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f314ab1c-7b25-4957-aed6-ff6276afd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_params = torch.load('/root/autodl-tmp/resnet50_places365.pth.tar', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6498f41-d9da-4bcb-82c0-ab775bfdb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for k,v in places_params['state_dict'].items():\n",
    "    if k.startswith('module.'):\n",
    "        params[k[7:]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a4fe9d-ed6b-4ef6-bdf2-35eeb0917f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = models.resnet50(False)\n",
    "places.fc = nn.Linear(2048,365)\n",
    "places.load_state_dict(params)\n",
    "places = nn.Sequential(*list(places.children())[:-2])\n",
    "places.eval()\n",
    "places.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d34b4420-6df3-4dd2-919b-c2ea4838fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = places(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289f303-62a2-454c-85d4-228597a40db7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# forward"
   ]
  },
  {
   "cell_type": "raw",
   "id": "889b3f48-a610-4515-8e7d-874b9e0e1aa3",
   "metadata": {},
   "source": [
    "idx = 0\n",
    "img = imgs[idx]\n",
    "feature = features[idx].mean(0)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7f71c8a-3b87-4df1-9b58-3ac881dd6559",
   "metadata": {},
   "source": [
    "weight = cv2.resize(np.array(feature), dsize=img.size)\n",
    "weight = (weight-np.min(weight))/(np.max(weight)-np.min(weight))\n",
    "plt.imshow(weight)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b58be843-34ed-47ea-98fa-c63c660d2af3",
   "metadata": {},
   "source": [
    "heatmap = cv2.applyColorMap(np.uint8(255 * weight), cv2.COLORMAP_JET)\n",
    "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "result = cv2.addWeighted(np.array(img), .5, heatmap, 0.5, 0)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8897a-4ec1-46f2-be64-7e1878e47bc4",
   "metadata": {},
   "source": [
    "# draw batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35339001-81a3-4863-bb6d-4f89d79519ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: results/bassl/0.png\n",
      "saving: results/bassl/1.png\n",
      "saving: results/bassl/2.png\n",
      "saving: results/bassl/3.png\n",
      "saving: results/bassl/4.png\n",
      "saving: results/bassl/5.png\n",
      "saving: results/bassl/6.png\n",
      "saving: results/bassl/7.png\n",
      "saving: results/bassl/8.png\n",
      "saving: results/bassl/9.png\n",
      "saving: results/bassl/10.png\n",
      "saving: results/bassl/11.png\n",
      "saving: results/bassl/12.png\n",
      "saving: results/bassl/13.png\n",
      "saving: results/bassl/14.png\n",
      "saving: results/bassl/15.png\n",
      "saving: results/bassl/16.png\n",
      "saving: results/bassl/17.png\n",
      "saving: results/shotcol/0.png\n",
      "saving: results/shotcol/1.png\n",
      "saving: results/shotcol/2.png\n",
      "saving: results/shotcol/3.png\n",
      "saving: results/shotcol/4.png\n",
      "saving: results/shotcol/5.png\n",
      "saving: results/shotcol/6.png\n",
      "saving: results/shotcol/7.png\n",
      "saving: results/shotcol/8.png\n",
      "saving: results/shotcol/9.png\n",
      "saving: results/shotcol/10.png\n",
      "saving: results/shotcol/11.png\n",
      "saving: results/shotcol/12.png\n",
      "saving: results/shotcol/13.png\n",
      "saving: results/shotcol/14.png\n",
      "saving: results/shotcol/15.png\n",
      "saving: results/shotcol/16.png\n",
      "saving: results/shotcol/17.png\n",
      "saving: results/imagenet/0.png\n",
      "saving: results/imagenet/1.png\n",
      "saving: results/imagenet/2.png\n",
      "saving: results/imagenet/3.png\n",
      "saving: results/imagenet/4.png\n",
      "saving: results/imagenet/5.png\n",
      "saving: results/imagenet/6.png\n",
      "saving: results/imagenet/7.png\n",
      "saving: results/imagenet/8.png\n",
      "saving: results/imagenet/9.png\n",
      "saving: results/imagenet/10.png\n",
      "saving: results/imagenet/11.png\n",
      "saving: results/imagenet/12.png\n",
      "saving: results/imagenet/13.png\n",
      "saving: results/imagenet/14.png\n",
      "saving: results/imagenet/15.png\n",
      "saving: results/imagenet/16.png\n",
      "saving: results/imagenet/17.png\n",
      "saving: results/places/0.png\n",
      "saving: results/places/1.png\n",
      "saving: results/places/2.png\n",
      "saving: results/places/3.png\n",
      "saving: results/places/4.png\n",
      "saving: results/places/5.png\n",
      "saving: results/places/6.png\n",
      "saving: results/places/7.png\n",
      "saving: results/places/8.png\n",
      "saving: results/places/9.png\n",
      "saving: results/places/10.png\n",
      "saving: results/places/11.png\n",
      "saving: results/places/12.png\n",
      "saving: results/places/13.png\n",
      "saving: results/places/14.png\n",
      "saving: results/places/15.png\n",
      "saving: results/places/16.png\n",
      "saving: results/places/17.png\n"
     ]
    }
   ],
   "source": [
    "for method in ['bassl','shotcol','imagenet','places']:\n",
    "    features = eval(method)(tensors)\n",
    "    for idx in range(len(imgs)):\n",
    "        img = imgs[idx]\n",
    "        feature = features[idx].mean(0)\n",
    "        \n",
    "        weight = cv2.resize(np.array(feature), dsize=img.size)\n",
    "        weight = (weight-np.min(weight))/(np.max(weight)-np.min(weight))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * weight), cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        result = cv2.addWeighted(np.array(img), .6, heatmap, .4, 0)\n",
    "        \n",
    "        name = f'results/{method}/{idx}.png'\n",
    "        print('saving:',name)\n",
    "        img = Image.fromarray(result)\n",
    "        img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68cafd35-b2d6-45d1-a795-11aba5f6832d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: results/mean/0.png\n",
      "saving: results/mean/1.png\n",
      "saving: results/mean/2.png\n",
      "saving: results/mean/3.png\n",
      "saving: results/mean/4.png\n",
      "saving: results/mean/5.png\n",
      "saving: results/mean/6.png\n",
      "saving: results/mean/7.png\n",
      "saving: results/mean/8.png\n",
      "saving: results/mean/9.png\n",
      "saving: results/mean/10.png\n",
      "saving: results/mean/11.png\n",
      "saving: results/mean/12.png\n",
      "saving: results/mean/13.png\n",
      "saving: results/mean/14.png\n",
      "saving: results/mean/15.png\n",
      "saving: results/mean/16.png\n",
      "saving: results/mean/17.png\n"
     ]
    }
   ],
   "source": [
    "features = (imagenet(tensors)+places(tensors))/2\n",
    "for idx in range(len(imgs)):\n",
    "    img = imgs[idx]\n",
    "    feature = features[idx].mean(0)\n",
    "\n",
    "    weight = cv2.resize(np.array(feature), dsize=img.size)\n",
    "    weight = (weight-np.min(weight))/(np.max(weight)-np.min(weight))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * weight), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.addWeighted(np.array(img), .6, heatmap, .4, 0)\n",
    "\n",
    "    name = f'results/mean/{idx}.png'\n",
    "    print('saving:',name)\n",
    "    img = Image.fromarray(result)\n",
    "    img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8c577-af5a-4e16-b07b-137aa5b003f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
